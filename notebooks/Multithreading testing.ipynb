{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "from numpy.random import normal, multivariate_normal\n",
    "from scipy.stats import norm\n",
    "import P_binary\n",
    "import P_random\n",
    "import P_posterior\n",
    "import const as c\n",
    "from astropy.table import Table\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def worker():\n",
    "    name = multiprocessing.current_process().name\n",
    "    print name, 'Starting'\n",
    "    time.sleep(2)\n",
    "    print name, 'Exiting'\n",
    "\n",
    "def my_service():\n",
    "    name = multiprocessing.current_process().name\n",
    "    print name, 'Starting'\n",
    "    time.sleep(3)\n",
    "    print name, 'Exiting'\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "size_integrate = 10          # Number of samples for delta mu integration for initial search\n",
    "size_integrate_full = 1000  # Number of samples for delta mu integration for possible matches\n",
    "\n",
    "\n",
    "def match_binaries(t):\n",
    "    \"\"\" Function to match binaries within a catalog\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    t : ndarray\n",
    "        Catalog for self-compare for matching\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prob_out : ndarray\n",
    "        Set of matched pairs, their IDs, and their probabilities\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Start time\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    # Generate simulated binaries\n",
    "    print \"Generating binaries...\"\n",
    "    P_binary.generate_binary_set(num_sys=100000)\n",
    "\n",
    "\n",
    "    # Generate random alignment KDEs using first entry as a test position\n",
    "    P_random.mu_kde = None\n",
    "    P_random.pos_kde = None\n",
    "    pos_density = P_random.get_sigma_pos(t['ra'][0], t['dec'][0], catalog=t, method='kde')\n",
    "    pm_density = P_random.get_sigma_mu(t['mu_ra'][0], t['mu_dec'][0], catalog=t, method='kde')\n",
    "\n",
    "\n",
    "    # Now, let's calculate the probabilities\n",
    "    length = len(t)\n",
    "    print \"We are testing\", length, \"stars...\"\n",
    "\n",
    "    dtype = [('i_1','i4'),('i_2','i4'),('ID_1','i4'),('ID_2','i4'),('P_random','f8'),('P_binary','f8'),('P_posterior','f8')]\n",
    "    prob_out = np.array([], dtype=dtype)\n",
    "\n",
    "\n",
    "    for i in np.arange(length):\n",
    "\n",
    "        if i%1000 == 0: print i, time.time()-start\n",
    "\n",
    "        jobs = []\n",
    "            \n",
    "        # Get ids of all stars within 1 degree and parallaxes in agreement within 3-sigma\n",
    "        i_star2 = np.arange(length - i - 1) + i + 1\n",
    "        theta = P_random.get_theta_proj_degree(t['ra'][i], t['dec'][i], t['ra'][i_star2], t['dec'][i_star2])\n",
    "        delta_plx = np.abs(t['plx'][i]-t['plx'][i_star2])\n",
    "        delta_plx_err = np.sqrt(t['plx_err'][i]**2 + t['plx_err'][i_star2]**2)\n",
    "        ids_good = np.intersect1d(i_star2[np.where(theta < 1.0)[0]], i_star2[np.where(delta_plx < 3.0*delta_plx_err)[0]])\n",
    "\n",
    "        # Move on if no matches within 1 degree\n",
    "        if len(ids_good) == 0: continue\n",
    "\n",
    "\n",
    "\n",
    "        # Select random delta mu's for Monte Carlo integration over observational uncertainties\n",
    "        theta_good = P_random.get_theta_proj_degree(t['ra'][i], t['dec'][i], t['ra'][ids_good], t['dec'][ids_good])\n",
    "        delta_mu_ra_err = np.sqrt(t['mu_ra_err'][i]**2 + t['mu_ra_err'][ids_good]**2)\n",
    "        delta_mu_dec_err = np.sqrt(t['mu_dec_err'][i]**2 + t['mu_dec_err'][ids_good]**2)\n",
    "        delta_mu_err = np.sqrt(delta_mu_ra_err**2 + delta_mu_dec_err**2)\n",
    "        delta_mu_ra = t['mu_ra'][i] - t['mu_ra'][ids_good]\n",
    "        delta_mu_dec = t['mu_dec'][i] - t['mu_dec'][ids_good]\n",
    "        delta_mu = np.sqrt(delta_mu_ra**2 + delta_mu_dec**2)\n",
    "        mu_diff_3sigma = delta_mu - 3.0*delta_mu_err\n",
    "\n",
    "\n",
    "\n",
    "        # Identify potential matches as ones with non-zero P(binary)\n",
    "        mu_diff_vector = np.amax(np.vstack([mu_diff_3sigma, 0.1*np.ones(len(ids_good))]), axis=0)\n",
    "        # dist in pc\n",
    "        min_dist = 1.0e3 / np.amax(np.vstack([np.ones(len(ids_good)) * (t['plx'][i]+3.0*t['plx_err'][i]), t['plx'][ids_good]+3.0*t['plx_err'][ids_good]]), axis=0)\n",
    "        # projected separation in pc\n",
    "        proj_sep_vector = (theta_good*np.pi/180.0) * min_dist * (c.pc_to_cm / c.Rsun_to_cm)\n",
    "        # Transverse velocity vector in km/s\n",
    "        delta_v_trans_vector = (mu_diff_vector/1.0e3/3600.0*np.pi/180.0) * min_dist * (c.pc_to_cm/1.0e5) / (c.yr_to_sec)\n",
    "        ids_good_binary = np.where(P_binary.get_P_binary(proj_sep_vector, delta_v_trans_vector) > 0.0)[0]\n",
    "\n",
    "        # If no matches, move on\n",
    "        if len(ids_good_binary) == 0: continue\n",
    "\n",
    "        # Ids of all matches\n",
    "        ids_good_binary_all = ids_good[ids_good_binary]\n",
    "\n",
    "\n",
    "\n",
    "        # More precise integration for potential matches\n",
    "        for k in np.arange(len(ids_good_binary_all)):\n",
    "\n",
    "            # IDs for the secondary\n",
    "            j = ids_good_binary_all[k]\n",
    "\n",
    "            # Star arrays\n",
    "            star1 = t['ra'][i], t['dec'][i], t['mu_ra'][i], t['mu_dec'][i], t['mu_ra_err'][i], t['mu_dec_err'][i]\n",
    "            star2 = t['ra'][j], t['dec'][j], t['mu_ra'][j], t['mu_dec'][j], t['mu_ra_err'][j], t['mu_dec_err'][j]\n",
    "\n",
    "\n",
    "            p = multiprocessing.Process(target=calc_P_posterior, args=(star1, star2, pos_density, pm_density, i, j, t,))\n",
    "            jobs.append(p)\n",
    "#             # Calculate the posterior probability\n",
    "#             prob_posterior, prob_random, prob_binary = calc_P_posterior(star1, star2, pos_density, pm_density, i, j, t)\n",
    "\n",
    "\n",
    "            p.start()\n",
    "\n",
    "        # Output to stdout non-zero probabilities\n",
    "        print i, j, t['NLTT'][i], t['NLTT'][j], t['ID'][i], t['ID'][j], prob_random, prob_binary, prob_posterior\n",
    "\n",
    "\n",
    "        # Select potential matches\n",
    "        # if prob_posterior > 0.5:\n",
    "        if prob_posterior > 1.0e-2:\n",
    "            prob_temp = np.zeros(1, dtype=dtype)\n",
    "            prob_temp[0] = i, j, t['ID'][i], t['ID'][j], prob_random, prob_binary, prob_posterior\n",
    "            prob_out = np.append(prob_out, prob_temp)\n",
    "\n",
    "\n",
    "    print \"Elapsed time:\", time.time() - start, \"seconds\"\n",
    "\n",
    "    return prob_out\n",
    "\n",
    "\n",
    "def calc_P_posterior(star1, star2, pos_density, pm_density, id1, id2, t):\n",
    "\n",
    "\n",
    "    ####################### Binary Likelihood #########################\n",
    "    # Angular separation\n",
    "    theta = P_random.get_theta_proj_degree(t['ra'][id1], t['dec'][id1], t['ra'][id2], t['dec'][id2])\n",
    "\n",
    "\n",
    "    # Proper motion uncertainties\n",
    "    delta_mu_ra_err = np.sqrt(t['mu_ra_err'][id1]**2 + t['mu_ra_err'][id2]**2)\n",
    "    delta_mu_dec_err = np.sqrt(t['mu_dec_err'][id1]**2 + t['mu_dec_err'][id2]**2)\n",
    "\n",
    "\n",
    "    # Recalculate binary probabilities\n",
    "    delta_mu_ra_sample = normal(loc=(t['mu_ra'][id1] - t['mu_ra'][id2]), \\\n",
    "                                             scale=delta_mu_ra_err, \\\n",
    "                                             size=size_integrate_full)\n",
    "    delta_mu_dec_sample = normal(loc=(t['mu_dec'][id1] - t['mu_dec'][id2]), \\\n",
    "                                              scale=delta_mu_dec_err, \\\n",
    "                                              size=size_integrate_full)\n",
    "    delta_mu_sample = np.sqrt(delta_mu_ra_sample**2 + delta_mu_dec_sample**2)\n",
    "\n",
    "    # Generate random parallaxes from uncertainties in primary star\n",
    "    plx_sample = normal(loc=t['plx'][id1], scale=t['plx_err'][id1], \\\n",
    "                                              size=size_integrate_full)\n",
    "\n",
    "    # Distance in pc is just parallax in asec\n",
    "    dist_sample = 1.0e3 / plx_sample  # convert from mas to asec\n",
    "\n",
    "    # Convert from proper motion difference (mas/yr) to transverse velocity difference (km/s)\n",
    "    delta_v_trans = (delta_mu_sample/1.0e3/3600.0*np.pi/180.0) * dist_sample * (c.pc_to_cm/1.0e5) / (c.yr_to_sec)\n",
    "\n",
    "    # Find the physical separation (Rsun) from the angular separation (degree)\n",
    "    proj_sep = (theta*np.pi/180.0) * dist_sample * (c.pc_to_cm / c.Rsun_to_cm)\n",
    "\n",
    "    # Find binary probabilities\n",
    "    prob_tmp = P_binary.get_P_binary(proj_sep, delta_v_trans)\n",
    "\n",
    "    # Now, let's add probabilities for second star's parallax to match\n",
    "    prob_plx_2 = norm.pdf(plx_sample, loc=t['plx'][id2], scale=t['plx_err'][id2])\n",
    "\n",
    "    # Parallax prior -> Lenz-Kelker bias goes here. For now, assume flat prior\n",
    "    prob_plx_prior = 1.0\n",
    "\n",
    "    # Monte Carlo integral\n",
    "    prob_binary = 1.0/size_integrate_full * np.sum(prob_tmp * prob_plx_2 * prob_plx_prior)\n",
    "\n",
    "\n",
    "\n",
    "    ####################### Random Alignment Likelihood #########################\n",
    "    # Random Alignment densities\n",
    "    pos_density = P_random.get_sigma_pos(t['ra'][id1], t['dec'][id1], catalog=t, method='kde')\n",
    "    pm_density = P_random.get_sigma_mu(t['mu_ra'][id1], t['mu_dec'][id1], catalog=t, method='kde')\n",
    "\n",
    "\n",
    "    # Calculate random alignment probabilities\n",
    "    prob_random, prob_pos, prob_mu = P_random.get_P_random_alignment(star1[0], star1[1], star2[0], star2[1],\n",
    "                                      star1[2], star1[3], star2[2], star2[3],\n",
    "                                      delta_mu_ra_err=delta_mu_ra_err, delta_mu_dec_err=delta_mu_dec_err,\n",
    "                                      pos_density=pos_density, pm_density=pm_density,\n",
    "                                      catalog=t)\n",
    "\n",
    "    # Now, need to compute parallax integrals\n",
    "    # Lenz-Kelker bias goes here. For now, assume flat prior, so integrals equal unity\n",
    "    prob_plx_1 = 1.0\n",
    "    prob_plx_2 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "    ####################### Posterior Probability #########################\n",
    "    # Save those pairs with posterior probabilities above 50%\n",
    "    return c.f_bin * prob_binary / (prob_random + c.f_bin * prob_binary), prob_random, prob_binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Hipparchos/rNLTT joint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in sample from Tycho-2 table\n",
    "filename = ('../data/rNLTT/catalog_tabs.dat')\n",
    "t_full = Table.read(filename, format='ascii', guess=True)\n",
    "\n",
    "# Change proper motion units from asec/yr to mas/yr\n",
    "t_full['mu_ra'] = 1.0e3*t_full['mu_ra']\n",
    "t_full['mu_dec'] = 1.0e3*t_full['mu_dec']\n",
    "t_full['mu_ra_err'] = 1.0e3*t_full['mu_ra_err']\n",
    "t_full['mu_dec_err'] = 1.0e3*t_full['mu_dec_err']\n",
    "\n",
    "# Select only stars with proper motion uncertainties greater than 1 mas/yr - remove junk\n",
    "ids_good = np.intersect1d(np.where(t_full['mu_ra_err'] >= 0.1), np.where(t_full['mu_dec_err'] >= 0.1))\n",
    "t = t_full[ids_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in sample from Tycho-2 table\n",
    "filename = ('../data/hipparchos/hip2.dat')\n",
    "readme = ('../data/hipparchos/Readme')\n",
    "hip = Table.read(filename, format='cds', guess=False, readme=readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_hip_tmp = t_full[np.where(t_full['HIP']!=0)[0]]\n",
    "\n",
    "# Only non-repeating entries\n",
    "vals, indices = np.unique(t_hip_tmp['NLTT'], return_index=True)\n",
    "t_hip = t_hip_tmp[indices]\n",
    "\n",
    "\n",
    "dtype = [('ID','i8'),('NLTT','i8'),('ra','f8'),('dec','f8'),('mu_ra','f8'),('mu_dec','f8'), \\\n",
    "         ('mu_ra_err','f8'),('mu_dec_err','f8'),('B','f8'),('V','f8'), \\\n",
    "         ('plx','f8'),('plx_err','f8')]\n",
    "\n",
    "t = np.zeros(len(t_hip), dtype=dtype)\n",
    "t['ID'] = t_hip['HIP']\n",
    "t['NLTT'] = t_hip['NLTT']\n",
    "t['ra'] = t_hip['ra']\n",
    "t['dec'] = t_hip['dec']\n",
    "t['mu_ra'] = t_hip['mu_ra']\n",
    "t['mu_dec'] = t_hip['mu_dec']\n",
    "t['mu_ra_err'] = t_hip['mu_ra_err']\n",
    "t['mu_dec_err'] = t_hip['mu_dec_err']\n",
    "t['B'] = t_hip['B']\n",
    "t['V'] = t_hip['V']\n",
    "\n",
    "# Get parallaxes, by first finding indices matching two catalogs\n",
    "idx = np.zeros(len(t_hip), dtype='i8')\n",
    "for i in np.arange(len(t_hip)):\n",
    "    idx[i] =int(np.where(t_hip[i]['HIP'] == hip['HIP'])[0][0])\n",
    "    \n",
    "t['plx'] = hip['Plx'][idx]\n",
    "t['plx_err'] = hip['e_Plx'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating binaries...\n",
      "We are testing 8288 stars...\n",
      "0 4.81685614586\n",
      "13 17 139 173 428 473"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'prob_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-182e8c42539b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_binaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-7f586a73cb0a>\u001b[0m in \u001b[0;36mmatch_binaries\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Output to stdout non-zero probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NLTT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NLTT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_random\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'prob_random' is not defined"
     ]
    }
   ],
   "source": [
    "p_out = match_binaries(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
